import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import silhouette_score, davies_bouldin_score
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Segmentaci√≥n de Pacientes - C√°ncer de Mama",
    page_icon="üè•",
    layout="wide"
)

# T√≠tulo principal
st.title("üè• Sistema de Clustering para Segmentaci√≥n de Pacientes")
st.markdown("### An√°lisis No Supervisado - C√°ncer de Mama (Caja Blanca)")
st.markdown("---")

# Funci√≥n para cargar datos
@st.cache_data
def load_data():
    """Carga el dataset de Breast Cancer desde sklearn"""
    from sklearn.datasets import load_breast_cancer
    
    data = load_breast_cancer()
    df = pd.DataFrame(data.data, columns=data.feature_names)
    df['target'] = data.target  # 0=malignant, 1=benign (solo para referencia)
    
    return df, data.feature_names, data.target

# Cargar datos
df, feature_names, targets = load_data()

# Sidebar - Configuraci√≥n
st.sidebar.header("‚öôÔ∏è Configuraci√≥n del Modelo")
st.sidebar.markdown("---")

# Mostrar informaci√≥n del dataset
with st.expander("üìä Ver Dataset Original", expanded=False):
    col1, col2 = st.columns([3, 1])
    with col1:
        st.dataframe(df, use_container_width=True)
    with col2:
        st.metric("Pacientes", df.shape[0])
        st.metric("Caracter√≠sticas", df.shape[1])
        st.write("**Distribuci√≥n Real:**")
        st.write(f"üü¢ Benignos: {sum(targets == 1)}")
        st.write(f"üî¥ Malignos: {sum(targets == 0)}")

# Preparar datos para clustering
X = df.drop('target', axis=1)

# Normalizaci√≥n de datos
st.sidebar.subheader("üîß Preprocesamiento")
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
st.sidebar.success("‚úì Datos normalizados con StandardScaler")

# Selecci√≥n del algoritmo
st.sidebar.markdown("---")
st.sidebar.subheader("ü§ñ Algoritmo de Clustering")
algorithm = st.sidebar.selectbox(
    "Selecciona el algoritmo:",
    ["K-Means", "Clustering Jer√°rquico Aglomerativo"]
)

if algorithm == "K-Means":
    st.sidebar.info("üí° **K-Means:** Algoritmo r√°pido que minimiza la varianza intra-cluster. Ideal para clusters esf√©ricos.")
else:
    st.sidebar.info("üí° **Jer√°rquico:** Construye una jerarqu√≠a de clusters. No requiere especificar k inicialmente.")

# Configuraci√≥n de hiperpar√°metros
st.sidebar.markdown("---")
st.sidebar.subheader("üìà Hiperpar√°metros")

k_range = range(2, 11)
selected_k = st.sidebar.slider(
    "N√∫mero de clusters (k):",
    min_value=2,
    max_value=10,
    value=3,
    step=1,
    help="N√∫mero de grupos en los que se dividir√°n los pacientes"
)

# Bot√≥n para ejecutar an√°lisis
run_analysis = st.sidebar.button("üöÄ Ejecutar An√°lisis", type="primary", use_container_width=True)

if run_analysis:
    # Secci√≥n 1: Grid Search
    st.header("üìä 1. Optimizaci√≥n de Hiperpar√°metros (Grid Search)")
    st.markdown("**Objetivo:** Encontrar el n√∫mero √≥ptimo de clusters evaluando m√©tricas de calidad.")
    
    with st.spinner("üîÑ Calculando m√©tricas para diferentes valores de k..."):
        silhouette_scores = []
        davies_bouldin_scores = []
        
        for k in k_range:
            if algorithm == "K-Means":
                model = KMeans(n_clusters=k, random_state=42, n_init=10)
            else:
                model = AgglomerativeClustering(n_clusters=k)
            
            labels = model.fit_predict(X_scaled)
            sil_score = silhouette_score(X_scaled, labels)
            db_score = davies_bouldin_score(X_scaled, labels)
            
            silhouette_scores.append(sil_score)
            davies_bouldin_scores.append(db_score)
    
    # Gr√°ficos de m√©tricas
    col1, col2 = st.columns(2)
    
    with col1:
        fig_sil = px.line(
            x=list(k_range),
            y=silhouette_scores,
            markers=True,
            title="üìà Silhouette Score vs N√∫mero de Clusters",
            labels={'x': 'N√∫mero de Clusters (k)', 'y': 'Silhouette Score'}
        )
        fig_sil.add_hline(y=max(silhouette_scores), line_dash="dash", line_color="green", 
                          annotation_text="√ìptimo")
        fig_sil.update_traces(line_color='#1f77b4', marker=dict(size=10))
        fig_sil.update_layout(height=400)
        st.plotly_chart(fig_sil, use_container_width=True)
        st.info("üìà **Mayor Silhouette Score = Mejor separaci√≥n** (rango: -1 a 1)\n\n"
                "Valores > 0.5 = excelente | 0.25-0.5 = aceptable | < 0.25 = d√©bil")
    
    with col2:
        fig_db = px.line(
            x=list(k_range),
            y=davies_bouldin_scores,
            markers=True,
            title="üìâ Davies-Bouldin Index vs N√∫mero de Clusters",
            labels={'x': 'N√∫mero de Clusters (k)', 'y': 'Davies-Bouldin Index'}
        )
        fig_db.add_hline(y=min(davies_bouldin_scores), line_dash="dash", line_color="green",
                         annotation_text="√ìptimo")
        fig_db.update_traces(line_color='#ff7f0e', marker=dict(size=10))
        fig_db.update_layout(height=400)
        st.plotly_chart(fig_db, use_container_width=True)
        st.info("üìâ **Menor Davies-Bouldin = Mejor compactaci√≥n** (‚â• 0)\n\n"
                "Valores < 1 = excelente | 1-2 = aceptable | > 2 = d√©bil")
    
    # An√°lisis de k √≥ptimo
    optimal_k_sil = list(k_range)[np.argmax(silhouette_scores)]
    optimal_k_db = list(k_range)[np.argmin(davies_bouldin_scores)]
    
    st.markdown("### üéØ Recomendaci√≥n de k √ìptimo")
    col1, col2, col3 = st.columns(3)
    col1.metric("üìä Seg√∫n Silhouette", optimal_k_sil, 
                delta=f"Score: {max(silhouette_scores):.4f}")
    col2.metric("üìâ Seg√∫n Davies-Bouldin", optimal_k_db,
                delta=f"Index: {min(davies_bouldin_scores):.4f}")
    
    # An√°lisis inteligente
    if optimal_k_sil == optimal_k_db:
        col3.success(f"‚úÖ **Consenso:** k={optimal_k_sil}\n\nAmbas m√©tricas coinciden")
    else:
        col3.warning(f"‚ö†Ô∏è **Discrepancia:**\nSilhouette prefiere k={optimal_k_sil}\nDavies-Bouldin prefiere k={optimal_k_db}")
    
    # Explicaci√≥n contextual
    st.markdown("---")
    if optimal_k_sil == 2 and optimal_k_db == 2:
        st.info("üí° **Interpretaci√≥n Cl√≠nica:** Las m√©tricas sugieren **k=2 como √≥ptimo**, lo cual tiene sentido m√©dico "
                "ya que el dataset de Wisconsin est√° dise√±ado para clasificar tumores en dos categor√≠as naturales: "
                "**Benignos** y **Malignos**. Usar k > 2 crea subdivisiones dentro de estas categor√≠as.")
    
    st.markdown("---")
    
    # Secci√≥n 2: Clustering con k seleccionado
    st.header(f"üéØ 2. Resultados del Clustering (k={selected_k})")
    
    # Entrenar modelo
    if algorithm == "K-Means":
        final_model = KMeans(n_clusters=selected_k, random_state=42, n_init=10)
    else:
        final_model = AgglomerativeClustering(n_clusters=selected_k)
    
    clusters = final_model.fit_predict(X_scaled)
    
    # Calcular m√©tricas finales
    final_silhouette = silhouette_score(X_scaled, clusters)
    final_db = davies_bouldin_score(X_scaled, clusters)
    
    # Mostrar m√©tricas
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("üîµ Algoritmo", algorithm)
    col2.metric("üìä Silhouette Score", f"{final_silhouette:.4f}")
    col3.metric("üìâ Davies-Bouldin", f"{final_db:.4f}")
    
    # Calidad del clustering
    if final_silhouette > 0.5:
        quality = "Excelente ‚≠ê‚≠ê‚≠ê"
        quality_color = "green"
    elif final_silhouette > 0.25:
        quality = "Aceptable ‚≠ê‚≠ê"
        quality_color = "orange"
    else:
        quality = "D√©bil ‚≠ê"
        quality_color = "red"
    
    col4.markdown(f"**Calidad:** :{quality_color}[{quality}]")
    
    # Justificaci√≥n de k seleccionado
    if selected_k != optimal_k_sil:
        st.warning(f"‚ö†Ô∏è **Nota:** Seleccionaste k={selected_k}, pero el k √≥ptimo seg√∫n Silhouette es k={optimal_k_sil}. "
                   f"Esto puede ser v√°lido si buscas mayor **granularidad cl√≠nica** para estratificar tratamientos.")
    else:
        st.success(f"‚úÖ Seleccionaste el k √≥ptimo (k={selected_k}). ¬°Excelente elecci√≥n!")
    
    st.markdown("---")
    
    # Secci√≥n 3: Visualizaci√≥n PCA
    st.header("üî¨ 3. Visualizaci√≥n con PCA (An√°lisis de Componentes Principales)")
    st.markdown("**Reducci√≥n dimensional de 30 caracter√≠sticas a 2 componentes para visualizaci√≥n.**")
    
    with st.spinner("üîÑ Aplicando PCA y generando visualizaci√≥n..."):
        # Aplicar PCA
        pca = PCA(n_components=2, random_state=42)
        X_pca = pca.fit_transform(X_scaled)
        
        # Crear DataFrame
        df_pca = pd.DataFrame({
            'PC1': X_pca[:, 0],
            'PC2': X_pca[:, 1],
            'Cluster': clusters.astype(str),
            'Target_Real': df['target'].map({0: 'üî¥ Maligno', 1: 'üü¢ Benigno'})
        })
        
        var_explained = pca.explained_variance_ratio_
        
        col1, col2, col3 = st.columns(3)
        col1.metric("üìä Varianza PC1", f"{var_explained[0]:.2%}")
        col2.metric("üìä Varianza PC2", f"{var_explained[1]:.2%}")
        col3.metric("üìä Varianza Total", f"{var_explained.sum():.2%}")
        
        st.info(f"üí° Los 2 componentes principales capturan **{var_explained.sum():.1%}** de la informaci√≥n original "
                f"de las 30 caracter√≠sticas. Esto permite visualizar los clusters en un espacio 2D.")
        
        # Gr√°fico de dispersi√≥n
        fig_pca = px.scatter(
            df_pca,
            x='PC1',
            y='PC2',
            color='Cluster',
            title=f'üî¨ Visualizaci√≥n de Clusters en Espacio PCA ({algorithm}, k={selected_k})',
            labels={'PC1': f'PC1 ({var_explained[0]:.1%})', 'PC2': f'PC2 ({var_explained[1]:.1%})'},
            hover_data=['Target_Real'],
            color_discrete_sequence=px.colors.qualitative.Set2
        )
        fig_pca.update_traces(marker=dict(size=8, line=dict(width=0.5, color='white')))
        fig_pca.update_layout(height=600)
        st.plotly_chart(fig_pca, use_container_width=True)
    
    st.markdown("---")
    
    # Secci√≥n 4: Distribuci√≥n de Clusters
    st.header("üì¶ 4. Distribuci√≥n de Pacientes por Cluster")
    
    cluster_counts = pd.Series(clusters).value_counts().sort_index()
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        dist_df = pd.DataFrame({
            'Cluster': cluster_counts.index,
            'Pacientes': cluster_counts.values,
            'Porcentaje': (cluster_counts.values / len(clusters) * 100).round(2)
        })
        st.dataframe(dist_df, use_container_width=True, hide_index=True)
        
        # An√°lisis de balance
        max_pct = dist_df['Porcentaje'].max()
        min_pct = dist_df['Porcentaje'].min()
        
        if max_pct / min_pct > 5:
            st.warning(f"‚ö†Ô∏è **Desbalance:** Cluster m√°s grande es {max_pct/min_pct:.1f}x m√°s grande que el m√°s peque√±o")
        else:
            st.success("‚úÖ **Balance aceptable** entre clusters")
    
    with col2:
        fig_dist = px.bar(
            dist_df,
            x='Cluster',
            y='Pacientes',
            title="üìä N√∫mero de Pacientes por Cluster",
            text='Porcentaje',
            color='Cluster',
            color_discrete_sequence=px.colors.qualitative.Set2
        )
        fig_dist.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
        fig_dist.update_layout(showlegend=False, height=400)
        st.plotly_chart(fig_dist, use_container_width=True)
    
    st.markdown("---")
    
    # Secci√≥n 5: An√°lisis de Caracter√≠sticas
    st.header("üîç 5. Perfiles Cl√≠nicos por Cluster")
    st.markdown("**Caracter√≠sticas promedio de cada cluster (Top 10 m√°s relevantes):**")
    
    df_analysis = df.copy()
    df_analysis['Cluster'] = clusters
    
    # Top 10 caracter√≠sticas
    top_features = list(feature_names[:10])
    cluster_profiles = df_analysis.groupby('Cluster')[top_features].mean()
    
    # Mostrar tabla con formato
    try:
        st.dataframe(
            cluster_profiles.style.background_gradient(cmap='RdYlGn', axis=1).format("{:.2f}"),
            use_container_width=True
        )
    except:
        st.dataframe(cluster_profiles, use_container_width=True)
    
    # Interpretaci√≥n cl√≠nica autom√°tica
    st.markdown("### üè• Interpretaci√≥n Cl√≠nica de los Clusters")
    
    # Calcular severidad de cada cluster basado en mean radius y mean concavity
    severity_scores = cluster_profiles[['mean radius', 'mean concavity', 'mean concave points']].mean(axis=1)
    severity_ranking = severity_scores.sort_values()
    
    for idx, cluster_id in enumerate(severity_ranking.index):
        severity_level = idx + 1
        patients_count = cluster_counts[cluster_id]
        pct = (patients_count / len(clusters) * 100)
        
        if severity_level == 1:
            emoji = "üü¢"
            label = "Riesgo Bajo"
            interpretation = "Tumores peque√±os, regulares, probablemente **benignos**. Requieren monitoreo rutinario."
        elif severity_level == len(severity_ranking):
            emoji = "üî¥"
            label = "Riesgo Alto"
            interpretation = "Tumores grandes, irregulares, probablemente **malignos agresivos**. Requieren tratamiento inmediato."
        else:
            emoji = "üü°"
            label = f"Riesgo Medio ({severity_level}/{len(severity_ranking)})"
            interpretation = "Tumores con caracter√≠sticas intermedias. Requieren evaluaci√≥n detallada y posible intervenci√≥n."
        
        st.markdown(f"**{emoji} Cluster {cluster_id} - {label}**")
        st.markdown(f"- Pacientes: {patients_count} ({pct:.1f}%)")
        st.markdown(f"- {interpretation}")
        st.markdown("")
    
    st.markdown("---")
    
    # Comparaci√≥n con diagn√≥stico real
    st.header("üéØ 6. Validaci√≥n con Diagn√≥stico Real")
    
    df_validation = pd.DataFrame({
        'Cluster': clusters,
        'Diagn√≥stico_Real': df['target'].map({0: 'Maligno', 1: 'Benigno'})
    })
    
    validation_table = pd.crosstab(
        df_validation['Cluster'], 
        df_validation['Diagn√≥stico_Real'],
        margins=True
    )
    
    st.dataframe(validation_table, use_container_width=True)
    
    # Calcular pureza de clusters
    st.markdown("### üìä Pureza de Clusters")
    purities = []
    for cluster_id in range(selected_k):
        cluster_data = df_validation[df_validation['Cluster'] == cluster_id]
        if len(cluster_data) > 0:
            purity = cluster_data['Diagn√≥stico_Real'].value_counts().max() / len(cluster_data)
            dominant_class = cluster_data['Diagn√≥stico_Real'].value_counts().idxmax()
            purities.append({
                'Cluster': cluster_id,
                'Pureza': f"{purity:.1%}",
                'Clase Dominante': dominant_class,
                'Pacientes': len(cluster_data)
            })
    
    st.dataframe(pd.DataFrame(purities), use_container_width=True, hide_index=True)
    
    st.info("üí° **Pureza:** Porcentaje de la clase m√°s frecuente en cada cluster. "
            "Valores > 80% indican que el cluster captura bien una categor√≠a diagn√≥stica.")
    
    st.markdown("---")
    st.success("‚úÖ **An√°lisis completado exitosamente!** Los resultados est√°n listos para ser interpretados.")

else:
    st.info("üëà **Instrucciones:** Configura los par√°metros en el panel lateral y presiona **'Ejecutar An√°lisis'** para comenzar.")
    
    # Informaci√≥n del dataset
    st.header("‚ÑπÔ∏è Informaci√≥n del Dataset")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### üìä Wisconsin Diagnostic Breast Cancer Dataset
        
        **Descripci√≥n:**
        - 569 pacientes con diagn√≥stico de c√°ncer de mama
        - 30 caracter√≠sticas extra√≠das de im√°genes FNA (Fine Needle Aspiration)
        - 2 clases: Benigno (357) y Maligno (212)
        
        **Caracter√≠sticas incluyen:**
        - Radio, textura, per√≠metro, √°rea
        - Suavidad, compacidad, concavidad
        - Simetr√≠a, dimensi√≥n fractal
        - Para cada caracter√≠stica: media, error est√°ndar y "worst" (m√°s severo)
        """)
    
    with col2:
        st.markdown("""
        ### üéØ Objetivo del An√°lisis
        
        **Segmentar pacientes en grupos homog√©neos** usando t√©cnicas de clustering no supervisado para:
        
        1. Identificar patrones en los datos sin etiquetas
        2. Agrupar pacientes con caracter√≠sticas similares
        3. Estratificar niveles de riesgo
        4. Personalizar tratamientos m√©dicos
        5. Validar la capacidad de los algoritmos de descubrir las categor√≠as benigno/maligno
        
        **Algoritmos disponibles:** K-Means y Clustering Jer√°rquico
        """)
    
    st.markdown("---")
    
    # Gu√≠a de uso
    st.header("üìñ Gu√≠a de Uso")
    
    with st.expander("üîç ¬øC√≥mo usar esta aplicaci√≥n?"):
        st.markdown("""
        1. **Selecciona un algoritmo** en el panel lateral (K-Means o Jer√°rquico)
        2. **Ajusta el n√∫mero de clusters (k)** usando el slider
        3. **Presiona 'Ejecutar An√°lisis'** para ver los resultados
        4. **Analiza las m√©tricas** de Silhouette y Davies-Bouldin para evaluar calidad
        5. **Visualiza los clusters** en el espacio PCA
        6. **Interpreta los perfiles cl√≠nicos** de cada grupo
        7. **Valida con el diagn√≥stico real** para verificar precisi√≥n
        
        üí° **Recomendaci√≥n:** Comienza con k=2 o k=3 para ver la estructura b√°sica del dataset.
        """)
    
    st.markdown("---")
    st.markdown("**Desarrollado por:** Data Science Team | **Dataset:** UCI Machine Learning Repository | **Framework:** Streamlit + Docker")